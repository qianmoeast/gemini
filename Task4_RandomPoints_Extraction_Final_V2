# -*- coding: utf-8 -*-
# Task4_RandomPoints_Extraction_Integrated_Final.py
# 运行环境：ArcGIS Pro Python (arcpy)

import arcpy
from arcpy.sa import *
import os
import pandas as pd

# ================= 1. 参数配置区域 =================

# 工作空间设置
WORK_DIR = r"E:\paper1"
arcpy.env.workspace = WORK_DIR
arcpy.env.overwriteOutput = True
arcpy.CheckOutExtension("Spatial")

# --- 输入数据路径 ---
LULC_DIR = r"E:\paper1\shuju\LULC\4aligned_intersect"
CLIMATE_DIR = r"Z:\datasat\0000A\zhujx\raster\qixiangshuju\qihou2"
DEM_PATH = r"E:\paper1\shuju\dem\Extract_dem_250m.tif"
SLOPE_ASPECT_DIR = r"E:\paper1\shuju\Slope Aspect"
SOIL_DIR = r"E:\paper1\shuju\SoilGrids\SoilGrids_Step2"
GDP_DIR = r"E:\paper1\shuju\GDP\2res"
POP_DIR = r"E:\paper1\shuju\GlobPOP\2res"
TRANSITION_MAP_PATH = r"E:\paper1\result\Transition_Matrix\LULC_Transition_Map_1990_2020.tif"

# --- 输出路径 ---
OUTPUT_SHP_DIR = r"E:\paper1\shuju\shp"
OUTPUT_CSV_DIR = r"E:\paper1\excel"

if not os.path.exists(OUTPUT_SHP_DIR): os.makedirs(OUTPUT_SHP_DIR)
if not os.path.exists(OUTPUT_CSV_DIR): os.makedirs(OUTPUT_CSV_DIR)

# 目标年份
TARGET_YEARS = [1990, 1995, 2000, 2005, 2010, 2015, 2020]

# 随机点设置
NUM_POINTS = 100000 
MIN_DISTANCE = "1 Kilometers"

# 湿地提取筛选代码 (1:水田, 2:库塘, 3:滩涂, 4:沼泽, 5:河流)
VALID_WET_CODES = [1, 2, 3, 4, 5]

# ================= 2. 辅助函数 =================

def find_file(directory, keywords, ext=".tif"):
    """模糊查找文件"""
    if not os.path.exists(directory): return None
    for f in os.listdir(directory):
        if f.endswith(ext) and all(k in f for k in keywords):
            return os.path.join(directory, f)
    return None

def get_year_suffix(year):
    """生成年份后缀，例如 1990 -> 90"""
    return str(year)[-2:]

# ================= 3. 核心流程 =================

def main():
    print(">>> 开始执行集成提取任务...")

    # --- 步骤 1: 生成或加载随机点 ---
    # 我们将创建一个 Master Shapefile，所有数据都提取到这里
    master_shp = os.path.join(OUTPUT_SHP_DIR, "Master_Sample_Points.shp")
    
    if not arcpy.Exists(master_shp):
        print("  正在生成随机点模板 (基于2020年LULC)...")
        lulc_2020 = os.path.join(LULC_DIR, "2020.tif")
        if not os.path.exists(lulc_2020):
            print("  [错误] 找不到2020年LULC数据，无法生成点。")
            return
            
        # 提取有效区域 (1-4) 用于布点
        temp_poly = os.path.join(OUTPUT_SHP_DIR, "Temp_Valid_Area.shp")
        ras = Raster(lulc_2020)
        # 注意：这里根据您的需求，如果是要研究全域，可以用 >0；
        # 如果只关注湿地变化区域，可以用 (ras >= 1) & (ras <= 5)
        # 这里假设只要有 LULC 数据的区域都可以布点
        valid_area = Con(ras > 0, 1) 
        arcpy.conversion.RasterToPolygon(valid_area, temp_poly, "SIMPLIFY", "VALUE")
        
        arcpy.management.CreateRandomPoints(
            out_path=OUTPUT_SHP_DIR, 
            out_name="Master_Sample_Points.shp",
            constraining_feature_class=temp_poly,
            number_of_points_or_field=NUM_POINTS,
            minimum_allowed_distance=MIN_DISTANCE
        )
        arcpy.management.Delete(temp_poly)
        print(f"  随机点已生成: {master_shp}")
    else:
        print(f"  使用现有的主点文件: {master_shp}")

    # --- 步骤 2: 构建提取列表 (静态变量 + 动态变量) ---
    extract_list = []
    
    # A. 静态变量 (不随年份变化)
    print("  准备静态变量...")
    if os.path.exists(DEM_PATH): extract_list.append([DEM_PATH, "DEM"])
    
    slope = find_file(SLOPE_ASPECT_DIR, ["slope"], ".tif")
    if slope: extract_list.append([slope, "Slope"])
    
    aspect = find_file(SLOPE_ASPECT_DIR, ["aspect"], ".tif")
    if aspect: extract_list.append([aspect, "Aspect"])
    
    # LUCC_C (转移矩阵) 是静态的，所有年份都用同一列值
    if os.path.exists(TRANSITION_MAP_PATH): extract_list.append([TRANSITION_MAP_PATH, "LUCC_C"])
    
    # 土壤数据
    if os.path.exists(SOIL_DIR):
        for f in os.listdir(SOIL_DIR):
            if f.endswith(".tif"):
                # 简化名称: TP_SoilGrids_bdod_5 -> bdod_5
                fname = os.path.splitext(f)[0].replace("TP_SoilGrids_", "")
                extract_list.append([os.path.join(SOIL_DIR, f), fname])

    # B. 动态变量 (随年份变化)
    print("  准备动态年份变量...")
    
    for year in TARGET_YEARS:
        ys = get_year_suffix(year) # 90, 95...
        
        # 1. LULC -> LULC_90
        p = os.path.join(LULC_DIR, f"{year}.tif")
        if os.path.exists(p): extract_list.append([p, f"LULC_{ys}"])
        
        # 2. Climate -> pre_# -*- coding: utf-8 -*-
# Task4_RandomPoints_Extraction_Integrated.py
# 运行环境：ArcGIS Pro Python (arcpy)

import arcpy
from arcpy.sa import *
import os
import pandas as pd

# ================= 1. 参数配置区域 =================

# 工作空间设置
WORK_DIR = r"E:\paper1"
arcpy.env.workspace = WORK_DIR
arcpy.env.overwriteOutput = True
arcpy.CheckOutExtension("Spatial")

# --- 输入数据路径 ---
LULC_DIR = r"E:\paper1\shuju\LULC\4aligned_intersect"
CLIMATE_DIR = r"Z:\datasat\0000A\zhujx\raster\qixiangshuju\qihou2"
DEM_PATH = r"E:\paper1\shuju\dem\Extract_dem_250m.tif"
SLOPE_ASPECT_DIR = r"E:\paper1\shuju\Slope Aspect"
SOIL_DIR = r"E:\paper1\shuju\SoilGrids\SoilGrids_Step2"
GDP_DIR = r"E:\paper1\shuju\GDP\2res"
POP_DIR = r"E:\paper1\shuju\GlobPOP\2res"
TRANSITION_MAP_PATH = r"E:\paper1\result\Transition_Matrix\LULC_Transition_Map_1990_2020.tif"

# --- 输出路径 ---
OUTPUT_SHP_DIR = r"E:\paper1\shuju\shp"
OUTPUT_CSV_DIR = r"E:\paper1\excel"

if not os.path.exists(OUTPUT_SHP_DIR): os.makedirs(OUTPUT_SHP_DIR)
if not os.path.exists(OUTPUT_CSV_DIR): os.makedirs(OUTPUT_CSV_DIR)

# 目标年份
TARGET_YEARS = [1990, 1995, 2000, 2005, 2010, 2015, 2020]

# 随机点设置
NUM_POINTS = 100000 
MIN_DISTANCE = "1 Kilometers"

# 湿地提取筛选代码 (1:水田, 2:库塘, 3:滩涂, 4:沼泽, 5:河流)
VALID_WET_CODES = [1, 2, 3, 4, 5]

# ================= 2. 辅助函数 =================

def find_file(directory, keywords, ext=".tif"):
    """模糊查找文件"""
    if not os.path.exists(directory): return None
    for f in os.listdir(directory):
        if f.endswith(ext) and all(k in f for k in keywords):
            return os.path.join(directory, f)
    return None

def get_year_suffix(year):
    """生成年份后缀，例如 1990 -> 90"""
    return str(year)[-2:]

# ================= 3. 核心流程 =================

def main():
    print(">>> 开始执行集成提取任务...")

    # --- 步骤 1: 生成或加载随机点 ---
    # 我们将创建一个 Master Shapefile，所有数据都提取到这里
    master_shp = os.path.join(OUTPUT_SHP_DIR, "Master_Sample_Points.shp")
    
    if not arcpy.Exists(master_shp):
        print("  正在生成随机点模板 (基于2020年LULC)...")
        lulc_2020 = os.path.join(LULC_DIR, "2020.tif")
        if not os.path.exists(lulc_2020):
            print("  [错误] 找不到2020年LULC数据，无法生成点。")
            return
            
        # 提取有效区域 (1-4) 用于布点
        temp_poly = os.path.join(OUTPUT_SHP_DIR, "Temp_Valid_Area.shp")
        ras = Raster(lulc_2020)
        valid_area = Con((ras >= 1) & (ras <= 4), 1) # 仅在湿地范围内布点
        arcpy.conversion.RasterToPolygon(valid_area, temp_poly, "SIMPLIFY", "VALUE")
        
        arcpy.management.CreateRandomPoints(
            out_path=OUTPUT_SHP_DIR, 
            out_name="Master_Sample_Points.shp",
            constraining_feature_class=temp_poly,
            number_of_points_or_field=NUM_POINTS,
            minimum_allowed_distance=MIN_DISTANCE
        )
        arcpy.management.Delete(temp_poly)
        print(f"  随机点已生成: {master_shp}")
    else:
        print(f"  使用现有的主点文件: {master_shp}")

    # --- 步骤 2: 构建提取列表 (静态变量 + 动态变量) ---
    # 为了避免 SHP 字段名超长 (max 10 chars)，我们需要精简字段名
    # 格式: 变量缩写 + 年份后缀 (如 LULC_90, GDPT_90)
    
    extract_list = []
    
    # A. 静态变量 (不随年份变化)
    print("  准备静态变量...")
    if os.path.exists(DEM_PATH): extract_list.append([DEM_PATH, "DEM"])
    
    slope = find_file(SLOPE_ASPECT_DIR, ["slope"], ".tif")
    if slope: extract_list.append([slope, "Slope"])
    
    aspect = find_file(SLOPE_ASPECT_DIR, ["aspect"], ".tif")
    if aspect: extract_list.append([aspect, "Aspect"])
    
    if os.path.exists(TRANSITION_MAP_PATH): extract_list.append([TRANSITION_MAP_PATH, "LUCC_C"])
    
    # 土壤数据
    if os.path.exists(SOIL_DIR):
        for f in os.listdir(SOIL_DIR):
            if f.endswith(".tif"):
                # 简化名称: TP_SoilGrids_bdod_5 -> bdod_5
                fname = os.path.splitext(f)[0].replace("TP_SoilGrids_", "")
                # 如果名字太长，可能需要进一步截断，但在SHP中通常允许到10字符
                # bdod_15 是7个字符，安全
                extract_list.append([os.path.join(SOIL_DIR, f), fname])

    # B. 动态变量 (随年份变化)
    print("  准备动态年份变量...")
    
    for year in TARGET_YEARS:
        ys = get_year_suffix(year) # 90, 95...
        
        # 1. LULC -> LULC_90
        p = os.path.join(LULC_DIR, f"{year}.tif")
        if os.path.exists(p): extract_list.append([p, f"LULC_{ys}"])
        
        # 2. Climate -> pre_90, tmp_90...
        for var in ["pre", "tmp", "tmx", "tmn", "pet"]:
            p = find_file(os.path.join(CLIMATE_DIR, var), [str(year)])
            if not p: p = find_file(CLIMATE_DIR, [var, str(year)])
            if p: extract_list.append([p, f"{var}_{ys}"])
            
        # 3. GDP -> GDPT_90, GDPP_90
        p = find_file(GDP_DIR, ["Total", str(year)])
        if p: extract_list.append([p, f"GDPT_{ys}"])
        
        p = find_file(GDP_DIR, ["PerCapita", str(year)])
        if p: extract_list.append([p, f"GDPP_{ys}"])
        
        # 4. POP -> POPC_90, POPD_90
        p = find_file(POP_DIR, ["Count", str(year)])
        if p: extract_list.append([p, f"POPC_{ys}"])
        
        p = find_file(POP_DIR, ["Density", str(year)])
        if p: extract_list.append([p, f"POPD_{ys}"])

    # --- 步骤 3: 执行提取 ---
    print(f"  正在将 {len(extract_list)} 个变量提取到 Shapefile (这可能需要几分钟)...")
    # 注意：如果SHP中已存在同名字段，ExtractMultiValuesToPoints可能会报错或重命名
    # 建议每次运行前清理SHP或者在一个新的副本上运行
    # 这里为了安全，我们创建一个工作副本
    working_shp = "in_memory/working_points"
    arcpy.management.CopyFeatures(master_shp, working_shp)
    
    try:
        arcpy.sa.ExtractMultiValuesToPoints(working_shp, extract_list, "NONE")
        print("  提取完成！正在导出数据...")
    except Exception as e:
        print(f"  [提取失败] {e}")
        return

    # --- 步骤 4: 转换为 DataFrame 并分割导出 ---
    
    # 获取所有字段
    fields = [f.name for f in arcpy.ListFields(working_shp) if f.type not in ['Geometry', 'OID']]
    
    # 读取数据 (包含坐标)
    data_rows = []
    with arcpy.da.SearchCursor(working_shp, ["OID@", "SHAPE@X", "SHAPE@Y"] + fields) as cursor:
        for row in cursor:
            data_rows.append(row)
            
    # 主 DataFrame (宽表)
    master_df = pd.DataFrame(data_rows, columns=["PointID", "Lon", "Lat"] + fields)
    
    # 识别静态字段 (不含年份后缀的)
    # 简单的判断逻辑：字段名最后不是 _数字
    static_cols = ["PointID", "Lon", "Lat"]
    for col in fields:
        # 如果列名没有年份后缀 (如 _90)，则归为静态
        is_dynamic = False
        for yr in TARGET_YEARS:
            if col.endswith(f"_{get_year_suffix(yr)}"):
                is_dynamic = True
                break
        if not is_dynamic:
            static_cols.append(col)
            
    # 逐年拆分并导出
    for year in TARGET_YEARS:
        ys = get_year_suffix(year)
        print(f"\n>>> 处理年份 {year} 的 CSV 输出...")
        
        # 1. 构建当前年份的列名映射
        # 我们需要把 LULC_90 还原为 LULC，把 GDPT_90 还原为 GDP_T
        current_cols = static_cols.copy()
        rename_dict = {}
        
        # 查找当前年份的动态列
        year_dynamic_cols = []
        for col in fields:
            if col.endswith(f"_{ys}"):
                year_dynamic_cols.append(col)
                # 生成标准列名 (去掉后缀，并还原缩写)
                base_name = col[:-3] # 去掉 _90
                # 还原特殊缩写
                if base_name == "GDPT": new_name = "GDP_T"
                elif base_name == "GDPP": new_name = "GDP_P"
                elif base_name == "POPC": new_name = "POP_C"
                elif base_name == "POPD": new_name = "POP_D"
                else: new_name = base_name
                
                rename_dict[col] = new_name
        
        # 提取数据
        df_year = master_df[current_cols + year_dynamic_cols].copy()
        
        # 重命名列
        df_year.rename(columns=rename_dict, inplace=True)
        
        # 添加年份列
        df_year["Year"] = year
        
        # 2. 导出 point_YYYY.csv (包含所有点，清洗空值)
        # 只要 LULC 列不为空即可 (或者其他关键变量)
        if "LULC" in df_year.columns:
            df_point = df_year.dropna(subset=["LULC"])
            p_out = os.path.join(OUTPUT_CSV_DIR, f"point_{year}.csv")
            df_point.to_csv(p_out, index=False, encoding='utf-8-sig')
            print(f"  已导出 point_{year}.csv (行数: {len(df_point)})")
            
            # 3. 导出 wet_YYYY.csv (筛选 LULC 1-5)
            # 确保 LULC 列存在且为数值
            df_wet = df_point[df_point["LULC"].isin(VALID_WET_CODES)]
            w_out = os.path.join(OUTPUT_CSV_DIR, f"wet_{year}.csv")
            df_wet.to_csv(w_out, index=False, encoding='utf-8-sig')
            print(f"  已导出 wet_{year}.csv   (行数: {len(df_wet)}) - 仅含 LULC 1-5")
        else:
            print(f"  [警告] 年份 {year} 缺少 LULC 数据，无法导出。")

    # 清理内存
    if arcpy.Exists(working_shp): arcpy.management.Delete(working_shp)
    print("\n所有任务完成！")

if __name__ == "__main__":
    main()
